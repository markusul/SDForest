[{"path":"https://markusul.github.io/SDForest/articles/SDForest.html","id":"causal-parents","dir":"Articles","previous_headings":"","what":"Causal parents","title":"SDForest","text":"Given estimated causal function, first question might want answer covariates causal parents response. intervene causal parents, expect response change. , can estimate functional dependency \\(Y\\) \\(X\\), \\(\\widehat{f(X)}\\) examine covariates important function. can directly compare importance pattern deconfounded estimator classical random forest estimated ranger. comparison plain counterpart always gives feeling strength confounding. confounding exists, SDForest() ranger::ranger() result similar models. graph , see variable importance varImp() deconfounded random forest plain random forest. scale meaning, see two true causal parents red getting clear higher variable importance SDForest. plain random forest distinguish spurious correlation true causation.  , looked variable importance non-regularized SDForest. two techniques better understand variables might causally important. first regularization path regPath(), plot variable importance varying regularization. option lets us visualize paths interactively better understand covariates seem robust importance model.","code":"# comparison to classical random forest fit_ranger <- ranger::ranger(Y ~ ., train_data, importance = 'impurity')  # comparison of variable importance imp_ranger <- fit_ranger$variable.importance imp_sdf <- fit$var_importance imp_col <- rep('black', length(imp_ranger)) imp_col[sim_data$j] <- 'red'  plot(imp_ranger, imp_sdf, col = imp_col, pch = 20,      xlab = 'ranger', ylab = 'SDForest',       main = 'Variable Importance') # check regularization path of variable importance path <- regPath(fit) plot(path, plotly = TRUE)"},{"path":"https://markusul.github.io/SDForest/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Markus Ulmer. Author, maintainer.","code":""},{"path":"https://markusul.github.io/SDForest/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Ulmer M (2024). SDForest: Spectrally Deconfounded Random Forest. R package version 0.1, https://markusul.github.io/SDForest/.","code":"@Manual{,   title = {SDForest: Spectrally Deconfounded Random Forest},   author = {Markus Ulmer},   year = {2024},   note = {R package version 0.1},   url = {https://markusul.github.io/SDForest/}, }"},{"path":"https://markusul.github.io/SDForest/index.html","id":"sdforest","dir":"","previous_headings":"","what":"Spectrally Deconfounded Random Forest","title":"Spectrally Deconfounded Random Forest","text":"Spectral Deconfounded Random Forests (SDForest) method estimating non-linear sparse causal effects presence unobserved confounding. SDForest shown nice estimate true causal function settings, observe many covariates, e.g. high-dimensional setting, fairly sparse confounding. (Ulmer?), (Guo, Ćevid, Bühlmann 2022), (Ćevid, Bühlmann, Meinshausen 2020)","code":""},{"path":"https://markusul.github.io/SDForest/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Spectrally Deconfounded Random Forest","text":"can install development version SDForest GitHub :","code":"# install.packages(\"devtools\") devtools::install_github(\"markusul/SDForest\")"},{"path":"https://markusul.github.io/SDForest/index.html","id":"usage","dir":"","previous_headings":"","what":"Usage","title":"Spectrally Deconfounded Random Forest","text":"basic example estimate causal effect X Y using SDForest. can learn analyzing sparse causal effects estimated SDForest vignette(\"SDForest\"). can also estimate just one Spectral Deconfounded Regression Tree using SDTree function.","code":"library(SDForest)  set.seed(42) # simulation of confounded data sim_data <- simulate_data_nonlinear(q = 2, p = 50, n = 100, m = 2) X <- sim_data$X Y <- sim_data$Y train_data <- data.frame(X, Y) # causal parents sim_data$j #> [1]  1 47 fit <- SDForest(Y ~ ., train_data) fit #> SDForest result #>  #> Number of trees:  100  #> Number of covariates:  50  #> OOB loss:  0.25  #> OOB spectral loss:  0.15 causal_Tree <- SDTree(Y ~ ., train_data, cp = 0.03)  # plot the causal tree causal_Tree #>        levelName     value           s  j        label decision n_samples #> 1  1             1.3487531  0.04517764 47  X47 <= 0.05                100 #> 2   ¦--1         0.9499773 -1.69331644 47 X47 <= -1.69       no        50 #> 3   ¦   ¦--1     0.3489319          NA NA          0.3       no         7 #> 4   ¦   °--3     0.9859657 -0.04564622 12 X12 <= -0.05      yes        43 #> 5   ¦       ¦--3 0.7622188          NA NA          0.8       no        23 #> 6   ¦       °--6 1.2424454          NA NA          1.2      yes        20 #> 7   °--2         1.7391441 -3.55015330 27 X27 <= -3.55      yes        50 #> 8       ¦--2     1.2038948          NA NA          1.2       no         5 #> 9       °--4     1.7789876 -0.46335890  1  X1 <= -0.46      yes        45 #> 10          ¦--4 1.3813340          NA NA          1.4       no        17 #> 11          °--5 2.0542768          NA NA          2.1      yes        28 plot(causal_Tree)"},{"path":"https://markusul.github.io/SDForest/reference/SDForest.html","id":null,"dir":"Reference","previous_headings":"","what":"Spectral Deconfounded Random Forest — SDForest","title":"Spectral Deconfounded Random Forest — SDForest","text":"Estimate regression Random Forest using spectral deconfounding. # TODO: add details","code":""},{"path":"https://markusul.github.io/SDForest/reference/SDForest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spectral Deconfounded Random Forest — SDForest","text":"","code":"SDForest(   formula = NULL,   data = NULL,   x = NULL,   y = NULL,   nTree = 100,   cp = 0,   min_sample = 5,   mtry = NULL,   mc.cores = 1,   Q_type = \"trim\",   trim_quantile = 0.5,   q_hat = 0,   Q = NULL,   A = NULL,   gamma = 0.5,   max_size = NULL,   gpu = FALSE,   return_data = TRUE,   mem_size = 1e+07,   leave_out_ind = NULL,   envs = NULL,   leave_envs_out_trees = NULL,   envs_trees = NULL,   max_candidates = 100 )"},{"path":"https://markusul.github.io/SDForest/reference/SDForest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spectral Deconfounded Random Forest — SDForest","text":"formula Object class formula describing model fit  form y ~ x1 + x2 + ... y numeric response  x1, x2, ... vectors covariates. Interactions supported. data Training data class data.frame containing variables model. x Predictor data, alternative formula data. y Response vector, alternative formula data. nTree Number trees grow. cp Complexity parameter, minimum loss decrease split node.  split performed loss decrease larger cp * initial_loss,  initial_loss loss initial estimate using stump. min_sample Minimum number observations per leaf.  split performed resulting leaves least  min_sample observations. mtry Number randomly selected covariates consider split,  NULL covariates available split. mc.cores Number cores use parallel processing, mc.cores > 1 trees estimated parallel. Q_type Type deconfounding, one 'trim', 'pca', 'no_deconfounding'.  'trim' corresponds Trim transform (Ćevid et al. 2020)   implemented Doubly debiased lasso (Guo et al. 2022) ,  'pca' PCA transformation(Paul et al. 2008) .  See get_Q. trim_quantile Quantile Trim transform,  needed trim DDL_trim, see get_Q. q_hat Assumed confounding dimension, needed pca,  see get_Q. Q Spectral transformation, NULL  internally estimated using get_Q. Numerical Anchor class matrix. See get_W. gamma Strength distributional robustness, \\(\\gamma \\[0, \\infty]\\).  See get_W. max_size Maximum number observations used bootstrap sample. NULL n samples replacement drawn. gpu TRUE, calculations performed GPU.  properly set . return_data TRUE, training data returned output. needed prune.SDForest, regPath.SDForest,  mergeForest. mem_size Amount split candidates can evaluated . trade-memory speed can decreased either memory sufficient gpu small. leave_out_ind Indices observations used training. envs Vector environments can used stratified tree fitting. leave_envs_out_trees Number trees estimated leaving one environments . Results number environments times number trees. SUPPORTED YET envs_trees Number trees estimated environment. Results number environments times number trees. SUPPORTED YET max_candidates Maximum number split points  proposed node covariate.","code":""},{"path":"https://markusul.github.io/SDForest/reference/SDForest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spectral Deconfounded Random Forest — SDForest","text":"Object class SDForest containing: predictions Vector predictions observation. forest List SDTree objects. var_names Names covariates. oob_loss --bag loss. MSE oob_SDloss --bag loss using spectral transformation. var_importance Variable importance. oob_ind List indices trees contain observation training set. oob_predictions --bag predictions. return_data TRUE following also returned: X Matrix covariates. Y Vector responses. Q Spectral transformation matrix.","code":""},{"path":"https://markusul.github.io/SDForest/reference/SDForest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Spectral Deconfounded Random Forest — SDForest","text":"Ćevid D, Bühlmann P, Meinshausen N (2020). “Spectral Deconfounding via Perturbed Sparse Linear Models.” J. Mach. Learn. Res., 21(1). ISSN 1532-4435. Guo Z, Ćevid D, Bühlmann P (2022). “Doubly debiased lasso: High-dimensional inference hidden confounding.” Annals Statistics, 50(3). ISSN 0090-5364, doi:10.1214/21-AOS2152 . Paul D, Bair E, Hastie T, Tibshirani R (2008). ““Preconditioning” feature selection regression high-dimensional problems.” Annals Statistics, 36(4). ISSN 0090-5364, doi:10.1214/009053607000000578 .","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/SDForest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Spectral Deconfounded Random Forest — SDForest","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/SDForest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spectral Deconfounded Random Forest — SDForest","text":"","code":"set.seed(42) # simulation of confounded data sim_data <- simulate_data_nonlinear(q = 2, p = 150, n = 100, m = 2) X <- sim_data$X Y <- sim_data$Y train_data <- data.frame(X, Y) # causal parents of y sim_data$j #> [1] 127 101  # comparison to classical random forest fit_ranger <- ranger::ranger(Y ~ ., train_data, importance = 'impurity')  fit <- SDForest(x = X, y = Y, nTree = 10, Q_type = 'pca', q_hat = 2) fit <- SDForest(Y ~ ., train_data) fit #> SDForest result #>  #> Number of trees:  100  #> Number of covariates:  150  #> OOB loss:  1.53  #> OOB spectral loss:  0.11   # comparison of variable importance imp_ranger <- fit_ranger$variable.importance imp_sdf <- fit$var_importance imp_col <- rep('black', length(imp_ranger)) imp_col[sim_data$j] <- 'red'  plot(imp_ranger, imp_sdf, col = imp_col, pch = 20,      xlab = 'ranger', ylab = 'SDForest',       main = 'Variable Importance')   # check regularization path of variable importance path <- regPath(fit) # out of bag error for different regularization plotOOB(path)  plot(path)   # detection of causal parent using stability selection stablePath <- stabilitySelection(fit) plot(stablePath)   # pruning of forest according to optimal out-of-bag performance fit <- prune(fit, cp = path$cp_min)  # partial functional dependence of y on the first causal parent dep <- partDependence(fit, sim_data$j[1]) plot(dep, n_examples = 100)"},{"path":"https://markusul.github.io/SDForest/reference/SDTree.html","id":null,"dir":"Reference","previous_headings":"","what":"Spectral Deconfounded Tree — SDTree","title":"Spectral Deconfounded Tree — SDTree","text":"Estimates regression tree using spectral deconfounding.  # TODO: add details","code":""},{"path":"https://markusul.github.io/SDForest/reference/SDTree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Spectral Deconfounded Tree — SDTree","text":"","code":"SDTree(   formula = NULL,   data = NULL,   x = NULL,   y = NULL,   max_leaves = NULL,   cp = 0.01,   min_sample = 5,   mtry = NULL,   fast = TRUE,   Q_type = \"trim\",   trim_quantile = 0.5,   q_hat = 0,   Q = NULL,   A = NULL,   gamma = 0.5,   gpu = FALSE,   mem_size = 1e+07,   max_candidates = 100 )"},{"path":"https://markusul.github.io/SDForest/reference/SDTree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Spectral Deconfounded Tree — SDTree","text":"formula Object class formula describing model fit  form y ~ x1 + x2 + ... y numeric response  x1, x2, ... vectors covariates. Interactions supported. data Training data class data.frame containing variables model. x Predictor data, alternative formula data. y Response vector, alternative formula data. max_leaves Maximum number leaves grown tree. cp Complexity parameter, minimum loss decrease split node.  split performed loss decrease larger cp * initial_loss,  initial_loss loss initial estimate using stump. min_sample Minimum number observations per leaf.  split performed resulting leaves least  min_sample observations. mtry Number randomly selected covariates consider split,  NULL covariates available split. fast TRUE, optimal splitts new leaves  evaluated previously optimal splitts potential loss-decrease reused.  FALSE possible splitts leaves reevaluated every split. Q_type Type deconfounding, one 'trim', 'pca', 'no_deconfounding'.  'trim' corresponds Trim transform (Ćevid et al. 2020)   implemented Doubly debiased lasso (Guo et al. 2022) ,  'pca' PCA transformation(Paul et al. 2008) .  See get_Q. trim_quantile Quantile Trim transform,  needed trim DDL_trim, see get_Q. q_hat Assumed confounding dimension, needed pca,  see get_Q. Q Spectral transformation, NULL  internally estimated using get_Q. Numerical Anchor class matrix. See get_W. gamma Strength distributional robustness, \\(\\gamma \\[0, \\infty]\\).  See get_W. gpu TRUE, calculations performed GPU.  properly set . mem_size Amount split candidates can evaluated . trade-memory speed can decreased either memory sufficient gpu small. max_candidates Maximum number split points  proposed node covariate.","code":""},{"path":"https://markusul.github.io/SDForest/reference/SDTree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Spectral Deconfounded Tree — SDTree","text":"Object class SDTree containing predictions Predictions training set. tree estimated tree class Node (Glur 2023) .  tree contains information splits resulting estimates. var_names Names covariates training data. var_importance Variable importance covariates. see varImp.SDTree","code":""},{"path":"https://markusul.github.io/SDForest/reference/SDTree.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Spectral Deconfounded Tree — SDTree","text":"Ćevid D, Bühlmann P, Meinshausen N (2020). “Spectral Deconfounding via Perturbed Sparse Linear Models.” J. Mach. Learn. Res., 21(1). ISSN 1532-4435. Glur C (2023). “data.tree: General Purpose Hierarchical Data Structure.” https://CRAN.R-project.org/package=data.tree. Guo Z, Ćevid D, Bühlmann P (2022). “Doubly debiased lasso: High-dimensional inference hidden confounding.” Annals Statistics, 50(3). ISSN 0090-5364, doi:10.1214/21-AOS2152 . Paul D, Bair E, Hastie T, Tibshirani R (2008). ““Preconditioning” feature selection regression high-dimensional problems.” Annals Statistics, 36(4). ISSN 0090-5364, doi:10.1214/009053607000000578 .","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/SDTree.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Spectral Deconfounded Tree — SDTree","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/SDTree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Spectral Deconfounded Tree — SDTree","text":"","code":"set.seed(42) # simulation of confounded data sim_data <- simulate_data_nonlinear(q = 2, p = 150, n = 100, m = 2) X <- sim_data$X Y <- sim_data$Y train_data <- data.frame(X, Y) # causal parents of y sim_data$j #> [1] 127 101  tree_plain_cv <- cvSDTree(Y ~ ., train_data, Q_type = \"no_deconfounding\") tree_plain <- SDTree(Y ~ ., train_data, Q_type = \"no_deconfounding\", cp = 0)  tree_causal_cv <- cvSDTree(Y ~ ., train_data) tree_causal <- SDTree(y = Y, x = X, cp = 0)  # check regularization path of variable importance path <- regPath(tree_causal) plot(path)   tree_plain <- prune(tree_plain, cp = tree_plain_cv$cp_min) tree_causal <- prune(tree_causal, cp = tree_causal_cv$cp_min) plot(tree_causal)  {\"x\":{\"diagram\":\"digraph {\\n\\n\\n\\n\\n  \\\"1\\\" [label = \\\"X127 <= 0.56\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"2\\\" [label = \\\"X101 <= -1.08\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"3\\\" [label = \\\"0.6\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"4\\\" [label = \\\"X101 <= 0.98\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"5\\\" [label = \\\"X127 <= -1.24\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"6\\\" [label = \\\"0.7\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"7\\\" [label = \\\"1.2\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"8\\\" [label = \\\"1.8\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"9\\\" [label = \\\"X101 <= 1.28\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"10\\\" [label = \\\"X101 <= -1.06\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"11\\\" [label = \\\"1.3\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"12\\\" [label = \\\"1.9\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"13\\\" [label = \\\"2.5\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n\\\"1\\\"->\\\"2\\\" [label = \\\"no\\\"] \\n\\\"1\\\"->\\\"9\\\" [label = \\\"yes\\\"] \\n\\\"2\\\"->\\\"3\\\" [label = \\\"no\\\"] \\n\\\"2\\\"->\\\"4\\\" [label = \\\"yes\\\"] \\n\\\"9\\\"->\\\"10\\\" [label = \\\"no\\\"] \\n\\\"9\\\"->\\\"13\\\" [label = \\\"yes\\\"] \\n\\\"4\\\"->\\\"5\\\" [label = \\\"no\\\"] \\n\\\"4\\\"->\\\"8\\\" [label = \\\"yes\\\"] \\n\\\"10\\\"->\\\"11\\\" [label = \\\"no\\\"] \\n\\\"10\\\"->\\\"12\\\" [label = \\\"yes\\\"] \\n\\\"5\\\"->\\\"6\\\" [label = \\\"no\\\"] \\n\\\"5\\\"->\\\"7\\\" [label = \\\"yes\\\"] \\n}\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}  plot(tree_plain)  {\"x\":{\"diagram\":\"digraph {\\n\\n\\n\\n\\n  \\\"1\\\" [label = \\\"X79 <= -0.72\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"2\\\" [label = \\\"X72 <= -2.32\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"3\\\" [label = \\\"-1\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"4\\\" [label = \\\"X27 <= 1.32\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"5\\\" [label = \\\"0.2\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"6\\\" [label = \\\"1.6\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"7\\\" [label = \\\"X127 <= 0.1\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"8\\\" [label = \\\"1.4\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"9\\\" [label = \\\"X105 <= -2.4\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"10\\\" [label = \\\"3.6\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n  \\\"11\\\" [label = \\\"2.4\\\", fillcolor = \\\"#FFFFFF\\\", fontcolor = \\\"#000000\\\"] \\n\\\"1\\\"->\\\"2\\\" [label = \\\"no\\\"] \\n\\\"1\\\"->\\\"7\\\" [label = \\\"yes\\\"] \\n\\\"2\\\"->\\\"3\\\" [label = \\\"no\\\"] \\n\\\"2\\\"->\\\"4\\\" [label = \\\"yes\\\"] \\n\\\"7\\\"->\\\"8\\\" [label = \\\"no\\\"] \\n\\\"7\\\"->\\\"9\\\" [label = \\\"yes\\\"] \\n\\\"4\\\"->\\\"5\\\" [label = \\\"no\\\"] \\n\\\"4\\\"->\\\"6\\\" [label = \\\"yes\\\"] \\n\\\"9\\\"->\\\"10\\\" [label = \\\"no\\\"] \\n\\\"9\\\"->\\\"11\\\" [label = \\\"yes\\\"] \\n}\",\"config\":{\"engine\":\"dot\",\"options\":null}},\"evals\":[],\"jsHooks\":[]}"},{"path":"https://markusul.github.io/SDForest/reference/copy.SDForest.html","id":null,"dir":"Reference","previous_headings":"","what":"Copy a forest — copy.SDForest","title":"Copy a forest — copy.SDForest","text":"Returns copy forest object. Might useful want keep original forest comparison pruned forest.","code":""},{"path":"https://markusul.github.io/SDForest/reference/copy.SDForest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Copy a forest — copy.SDForest","text":"","code":"# S3 method for SDForest copy(object, ...)"},{"path":"https://markusul.github.io/SDForest/reference/copy.SDForest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Copy a forest — copy.SDForest","text":"object SDForest object ... arguments passed methods.","code":""},{"path":"https://markusul.github.io/SDForest/reference/copy.SDForest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Copy a forest — copy.SDForest","text":"copy SDForest object","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/copy.SDForest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Copy a forest — copy.SDForest","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/copy.SDTree.html","id":null,"dir":"Reference","previous_headings":"","what":"Copy a tree — copy.SDTree","title":"Copy a tree — copy.SDTree","text":"Returns copy tree object.  Might useful want keep original tree comparison pruned tree.","code":""},{"path":"https://markusul.github.io/SDForest/reference/copy.SDTree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Copy a tree — copy.SDTree","text":"","code":"# S3 method for SDTree copy(object, ...)"},{"path":"https://markusul.github.io/SDForest/reference/copy.SDTree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Copy a tree — copy.SDTree","text":"object SDTree object ... arguments passed methods.","code":""},{"path":"https://markusul.github.io/SDForest/reference/copy.SDTree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Copy a tree — copy.SDTree","text":"copy SDTree object","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/copy.SDTree.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Copy a tree — copy.SDTree","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/cvSDTree.html","id":null,"dir":"Reference","previous_headings":"","what":"Cross-validation for the SDTree — cvSDTree","title":"Cross-validation for the SDTree — cvSDTree","text":"Estimates optimal complexity parameter SDTree using cross-validation.  transformations estimated training set validation set  separately ensure independence validation set.","code":""},{"path":"https://markusul.github.io/SDForest/reference/cvSDTree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Cross-validation for the SDTree — cvSDTree","text":"","code":"cvSDTree(   formula = NULL,   data = NULL,   x = NULL,   y = NULL,   max_leaves = NULL,   cp = 0.01,   min_sample = 5,   mtry = NULL,   fast = TRUE,   Q_type = \"trim\",   trim_quantile = 0.5,   q_hat = 0,   Q = NULL,   A = NULL,   gamma = 0.5,   gpu = FALSE,   mem_size = 1e+07,   max_candidates = 100,   n_cv = 3,   cp_seq = NULL,   mc.cores = 1 )"},{"path":"https://markusul.github.io/SDForest/reference/cvSDTree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Cross-validation for the SDTree — cvSDTree","text":"formula Object class formula describing model fit  form y ~ x1 + x2 + ... y numeric response  x1, x2, ... vectors covariates. Interactions supported. data Training data class data.frame containing variables model. x Predictor data, alternative formula data. y Response vector, alternative formula data. max_leaves Maximum number leaves grown tree. cp Complexity parameter, minimum loss decrease split node.  split performed loss decrease larger cp * initial_loss,  initial_loss loss initial estimate using stump. min_sample Minimum number observations per leaf.  split performed resulting leaves least  min_sample observations. mtry Number randomly selected covariates consider split,  NULL covariates available split. fast TRUE, optimal splitts new leaves  evaluated previously optimal splitts potential loss-decrease reused.  FALSE possible splitts leaves reevaluated every split. Q_type Type deconfounding, one 'trim', 'pca', 'no_deconfounding'.  'trim' corresponds Trim transform (Ćevid et al. 2020)   implemented Doubly debiased lasso (Guo et al. 2022) ,  'pca' PCA transformation(Paul et al. 2008) .  See get_Q. trim_quantile Quantile Trim transform,  needed trim DDL_trim, see get_Q. q_hat Assumed confounding dimension, needed pca,  see get_Q. Q Spectral transformation, NULL  internally estimated using get_Q. Numerical Anchor class matrix. See get_W. gamma Strength distributional robustness, \\(\\gamma \\[0, \\infty]\\).  See get_W. gpu TRUE, calculations performed GPU.  properly set . mem_size Amount split candidates can evaluated . trade-memory speed can decreased either memory sufficient gpu small. max_candidates Maximum number split points  proposed node covariate. n_cv Number folds cross-validation.  recommended use 5 folds number covariates  larger number observations. case spectral  transformation differ much validation data  substantially smaller training data. cp_seq Sequence complexity parameters cp compare using cross-validation,  NULL sequence 0 0.6 stepsize 0.002 used. mc.cores Number cores use parallel computation.","code":""},{"path":"https://markusul.github.io/SDForest/reference/cvSDTree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Cross-validation for the SDTree — cvSDTree","text":"list containing cp_min optimal complexity parameter. cp_table table containing complexity parameter,  mean standard deviation loss validation sets  complexity parameters. multiple complexity parameters result loss,  one largest complexity parameter shown.","code":""},{"path":"https://markusul.github.io/SDForest/reference/cvSDTree.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Cross-validation for the SDTree — cvSDTree","text":"Ćevid D, Bühlmann P, Meinshausen N (2020). “Spectral Deconfounding via Perturbed Sparse Linear Models.” J. Mach. Learn. Res., 21(1). ISSN 1532-4435. Guo Z, Ćevid D, Bühlmann P (2022). “Doubly debiased lasso: High-dimensional inference hidden confounding.” Annals Statistics, 50(3). ISSN 0090-5364, doi:10.1214/21-AOS2152 . Paul D, Bair E, Hastie T, Tibshirani R (2008). ““Preconditioning” feature selection regression high-dimensional problems.” Annals Statistics, 36(4). ISSN 0090-5364, doi:10.1214/009053607000000578 .","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/cvSDTree.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Cross-validation for the SDTree — cvSDTree","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/cvSDTree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Cross-validation for the SDTree — cvSDTree","text":"","code":"set.seed(1) n <- 50 X <- matrix(rnorm(n * 5), nrow = n) y <- sign(X[, 1]) * 3 + rnorm(n, 0, 5) cp <- cvSDTree(x = X, y = y, Q_type = 'no_deconfounding') cp #> $cp_min #>    cp  #> 0.076  #>  #> $cp_table #>          cp SDLoss mean SDLoss sd #>  [1,] 0.044    30.89977  4.336556 #>  [2,] 0.056    30.65170  5.398475 #>  [3,] 0.058    30.60373  5.370633 #>  [4,] 0.070    31.28713  5.866639 #>  [5,] 0.076    29.12192  5.155334 #>  [6,] 0.106    31.64469  3.284572 #>  [7,] 0.132    32.25506  3.564472 #>  [8,] 0.262    30.93818  5.837083 #>  [9,] 0.326    31.50641  6.333261 #> [10,] 0.362    33.27446  3.286796 #> [11,] 0.600    34.64608  4.718930 #>"},{"path":"https://markusul.github.io/SDForest/reference/f_four.html","id":null,"dir":"Reference","previous_headings":"","what":"Function of x on a fourier basis — f_four","title":"Function of x on a fourier basis — f_four","text":"Function x fourier basis subset covariates  causal effect Y using parameters beta. function given : $$f(x_i) = \\sum_{j = 1}^p 1_{j \\js} \\sum_{k = 1}^K \\beta_{j, k, 1}^{(1)} \\cos(0.1 k x_j) + \\beta_{j, k, 2}^{(2)} \\sin(0.1 k x_j)$$","code":""},{"path":"https://markusul.github.io/SDForest/reference/f_four.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function of x on a fourier basis — f_four","text":"","code":"f_four(x, beta, js)"},{"path":"https://markusul.github.io/SDForest/reference/f_four.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function of x on a fourier basis — f_four","text":"x vector covariates beta parameter vector function f(X) js indices causal covariates X","code":""},{"path":"https://markusul.github.io/SDForest/reference/f_four.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function of x on a fourier basis — f_four","text":"value function f(x)","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/f_four.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Function of x on a fourier basis — f_four","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/fromList.SDForest.html","id":null,"dir":"Reference","previous_headings":"","what":"SDForest fromList method — fromList.SDForest","title":"SDForest fromList method — fromList.SDForest","text":"Converts trees SDForest object class list class Node (Glur 2023) .","code":""},{"path":"https://markusul.github.io/SDForest/reference/fromList.SDForest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SDForest fromList method — fromList.SDForest","text":"","code":"# S3 method for SDForest fromList(object, ...)"},{"path":"https://markusul.github.io/SDForest/reference/fromList.SDForest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"SDForest fromList method — fromList.SDForest","text":"object SDForest object trees list format ... arguments passed methods.","code":""},{"path":"https://markusul.github.io/SDForest/reference/fromList.SDForest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"SDForest fromList method — fromList.SDForest","text":"SDForest object trees Node format","code":""},{"path":"https://markusul.github.io/SDForest/reference/fromList.SDForest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"SDForest fromList method — fromList.SDForest","text":"Glur C (2023). “data.tree: General Purpose Hierarchical Data Structure.” https://CRAN.R-project.org/package=data.tree.","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/fromList.SDForest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"SDForest fromList method — fromList.SDForest","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/fromList.SDTree.html","id":null,"dir":"Reference","previous_headings":"","what":"SDTree fromList method — fromList.SDTree","title":"SDTree fromList method — fromList.SDTree","text":"Converts tree SDTree object class list class Node (Glur 2023) .","code":""},{"path":"https://markusul.github.io/SDForest/reference/fromList.SDTree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SDTree fromList method — fromList.SDTree","text":"","code":"# S3 method for SDTree fromList(object, ...)"},{"path":"https://markusul.github.io/SDForest/reference/fromList.SDTree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"SDTree fromList method — fromList.SDTree","text":"object SDTree object tree list format ... arguments passed methods.","code":""},{"path":"https://markusul.github.io/SDForest/reference/fromList.SDTree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"SDTree fromList method — fromList.SDTree","text":"SDTree object tree Node format","code":""},{"path":"https://markusul.github.io/SDForest/reference/fromList.SDTree.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"SDTree fromList method — fromList.SDTree","text":"Glur C (2023). “data.tree: General Purpose Hierarchical Data Structure.” https://CRAN.R-project.org/package=data.tree.","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/fromList.SDTree.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"SDTree fromList method — fromList.SDTree","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/get_Q.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of spectral transformation — get_Q","title":"Estimation of spectral transformation — get_Q","text":"Estimates spectral transformation Q spectral deconfounding  shrinking leading singular values covariates.","code":""},{"path":"https://markusul.github.io/SDForest/reference/get_Q.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of spectral transformation — get_Q","text":"","code":"get_Q(X, type, trim_quantile = 0.5, q_hat = 0, gpu = FALSE)"},{"path":"https://markusul.github.io/SDForest/reference/get_Q.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of spectral transformation — get_Q","text":"X Numerical covariates class matrix. type Type deconfounding, one 'trim', 'pca', 'no_deconfounding'.  'trim' corresponds Trim transform (Ćevid et al. 2020)   implemented Doubly debiased lasso (Guo et al. 2022) ,  'pca' PCA transformation(Paul et al. 2008)   'no_deconfounding' Identity. trim_quantile Quantile Trim transform, needed trim. q_hat Assumed confounding dimension, needed pca. gpu TRUE, calculations performed GPU.  properly set .","code":""},{"path":"https://markusul.github.io/SDForest/reference/get_Q.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of spectral transformation — get_Q","text":"Q class matrix, spectral transformation matrix.","code":""},{"path":"https://markusul.github.io/SDForest/reference/get_Q.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation of spectral transformation — get_Q","text":"Ćevid D, Bühlmann P, Meinshausen N (2020). “Spectral Deconfounding via Perturbed Sparse Linear Models.” J. Mach. Learn. Res., 21(1). ISSN 1532-4435. Guo Z, Ćevid D, Bühlmann P (2022). “Doubly debiased lasso: High-dimensional inference hidden confounding.” Annals Statistics, 50(3). ISSN 0090-5364, doi:10.1214/21-AOS2152 . Paul D, Bair E, Hastie T, Tibshirani R (2008). ““Preconditioning” feature selection regression high-dimensional problems.” Annals Statistics, 36(4). ISSN 0090-5364, doi:10.1214/009053607000000578 .","code":""},{"path":"https://markusul.github.io/SDForest/reference/get_Q.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Estimation of spectral transformation — get_Q","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/get_Q.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of spectral transformation — get_Q","text":"","code":"set.seed(1) X <- matrix(rnorm(50 * 20), nrow = 50) Q_trim <- get_Q(X, 'trim') Q_pca <- get_Q(X, 'pca', q_hat = 5) Q_plain <- get_Q(X, 'no_deconfounding')"},{"path":"https://markusul.github.io/SDForest/reference/get_W.html","id":null,"dir":"Reference","previous_headings":"","what":"Estimation of anchor transformation — get_W","title":"Estimation of anchor transformation — get_W","text":"Estimates anchor transformation Anchor-Objective.  anchor transformation \\(W = -(1-\\sqrt{\\gamma}))\\Pi_A\\),  \\(\\Pi_A = (^TA)^{-1}^T\\). \\(\\gamma = 1\\) just identity.  \\(\\gamma = 0\\) corresponds residuals orthogonal projecting onto . large \\(\\gamma\\) close orthogonal projection onto , scaled \\(\\gamma\\). estimator \\(\\text{argmin}_f ||W(Y - f(X))||^2\\) corresponds Anchor-Regression Estimator  (Rothenhäusler et al. 2021) , (Bühlmann 2020) .","code":""},{"path":"https://markusul.github.io/SDForest/reference/get_W.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Estimation of anchor transformation — get_W","text":"","code":"get_W(A, gamma, intercept = FALSE, gpu = FALSE)"},{"path":"https://markusul.github.io/SDForest/reference/get_W.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Estimation of anchor transformation — get_W","text":"Numerical Anchor class matrix. gamma Strength distributional robustness, \\(\\gamma \\[0, \\infty]\\). intercept Logical, whether include intercept anchor. gpu TRUE, calculations performed GPU.  properly set .","code":""},{"path":"https://markusul.github.io/SDForest/reference/get_W.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Estimation of anchor transformation — get_W","text":"W class matrix, anchor transformation matrix.","code":""},{"path":"https://markusul.github.io/SDForest/reference/get_W.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Estimation of anchor transformation — get_W","text":"Bühlmann P (2020). “Invariance, Causality Robustness.” Statistical Science, 35(3). ISSN 0883-4237, doi:10.1214/19-STS721 . Rothenhäusler D, Meinshausen N, Bühlmann P, Peters J (2021). “Anchor Regression: Heterogeneous Data Meet Causality.” Journal Royal Statistical Society Series B: Statistical Methodology, 83(2), 215--246. ISSN 1369-7412, doi:10.1111/rssb.12398 .","code":""},{"path":"https://markusul.github.io/SDForest/reference/get_W.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Estimation of anchor transformation — get_W","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/get_W.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Estimation of anchor transformation — get_W","text":"","code":"set.seed(1) n <- 50 X <- matrix(rnorm(n * 1), nrow = n) Y <- 3 * X + rnorm(n) W <- get_W(X, gamma = 0) resid <- W %*% Y"},{"path":"https://markusul.github.io/SDForest/reference/get_cp_seq.SDForest.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the sequence of complexity parameters of a SDForest — get_cp_seq.SDForest","title":"Get the sequence of complexity parameters of a SDForest — get_cp_seq.SDForest","text":"function extracts sequence complexity parameters SDForest result changes SDForest pruned. cp values differ first three digits decimal point returned.","code":""},{"path":"https://markusul.github.io/SDForest/reference/get_cp_seq.SDForest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the sequence of complexity parameters of a SDForest — get_cp_seq.SDForest","text":"","code":"# S3 method for SDForest get_cp_seq(object, ...)"},{"path":"https://markusul.github.io/SDForest/reference/get_cp_seq.SDForest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the sequence of complexity parameters of a SDForest — get_cp_seq.SDForest","text":"object SDForest object ... arguments passed methods.","code":""},{"path":"https://markusul.github.io/SDForest/reference/get_cp_seq.SDForest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the sequence of complexity parameters of a SDForest — get_cp_seq.SDForest","text":"sequence complexity parameters","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/get_cp_seq.SDForest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get the sequence of complexity parameters of a SDForest — get_cp_seq.SDForest","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/get_cp_seq.SDTree.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the sequence of complexity parameters of a SDTree — get_cp_seq.SDTree","title":"Get the sequence of complexity parameters of a SDTree — get_cp_seq.SDTree","text":"function extracts sequence complexity parameters SDTree  result changes tree structure pruned. cp values differ first three digits decimal point returned.","code":""},{"path":"https://markusul.github.io/SDForest/reference/get_cp_seq.SDTree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the sequence of complexity parameters of a SDTree — get_cp_seq.SDTree","text":"","code":"# S3 method for SDTree get_cp_seq(object, ...)"},{"path":"https://markusul.github.io/SDForest/reference/get_cp_seq.SDTree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get the sequence of complexity parameters of a SDTree — get_cp_seq.SDTree","text":"object SDTree object ... arguments passed methods.","code":""},{"path":"https://markusul.github.io/SDForest/reference/get_cp_seq.SDTree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the sequence of complexity parameters of a SDTree — get_cp_seq.SDTree","text":"sequence complexity parameters","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/get_cp_seq.SDTree.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Get the sequence of complexity parameters of a SDTree — get_cp_seq.SDTree","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/mergeForest.html","id":null,"dir":"Reference","previous_headings":"","what":"Merge two forests — mergeForest","title":"Merge two forests — mergeForest","text":"function merges two forests.  trees combined variable importance  calculated weighted average two forests.  forests trained data,  predictions oob_predictions combined well.","code":""},{"path":"https://markusul.github.io/SDForest/reference/mergeForest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Merge two forests — mergeForest","text":"","code":"mergeForest(fit1, fit2)"},{"path":"https://markusul.github.io/SDForest/reference/mergeForest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Merge two forests — mergeForest","text":"fit1 first SDForest object fit2 second SDForest object","code":""},{"path":"https://markusul.github.io/SDForest/reference/mergeForest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Merge two forests — mergeForest","text":"merged SDForest object","code":""},{"path":"https://markusul.github.io/SDForest/reference/mergeForest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Merge two forests — mergeForest","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/partDependence.html","id":null,"dir":"Reference","previous_headings":"","what":"Partial dependence — partDependence","title":"Partial dependence — partDependence","text":"function calculates partial dependence model single variable. predictions made observations dataset varying  value variable interest. overall partial effect average predictions. (Friedman 2001)","code":""},{"path":"https://markusul.github.io/SDForest/reference/partDependence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Partial dependence — partDependence","text":"","code":"partDependence(object, j, X = NULL, mc.cores = 1)"},{"path":"https://markusul.github.io/SDForest/reference/partDependence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Partial dependence — partDependence","text":"object model object predict method takes newdata argument  returns predictions. j variable partial dependence calculated. Either column index variable dataset name variable. X dataset partial dependence calculated. contain variables dataset used train model. NULL, tries extract dataset model object. mc.cores Number cores use parallel computation.","code":""},{"path":"https://markusul.github.io/SDForest/reference/partDependence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Partial dependence — partDependence","text":"object class partDependence containing preds_mean average prediction value variable interest. x_seq sequence values variable interest. preds predictions value variable interest observation. j name variable interest. xj values variable interest dataset.","code":""},{"path":"https://markusul.github.io/SDForest/reference/partDependence.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Partial dependence — partDependence","text":"Friedman JH (2001). “Greedy Function Approximation: Gradient Boosting Machine.” Annals Statistics, 29(5), 1189--1232. ISSN 00905364, http://www.jstor.org/stable/2699986.","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/partDependence.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Partial dependence — partDependence","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/partDependence.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Partial dependence — partDependence","text":"","code":"set.seed(1) x <- rnorm(100) y <- sign(x) * 3 + rnorm(100) model <- SDTree(x = x, y = y, Q_type = 'no_deconfounding') pd <- partDependence(model, 1, X = x) plot(pd)"},{"path":"https://markusul.github.io/SDForest/reference/plot.SDTree.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot SDTree — plot.SDTree","title":"Plot SDTree — plot.SDTree","text":"Plot SDTree.","code":""},{"path":"https://markusul.github.io/SDForest/reference/plot.SDTree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot SDTree — plot.SDTree","text":"","code":"# S3 method for SDTree plot(x, ...)"},{"path":"https://markusul.github.io/SDForest/reference/plot.SDTree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot SDTree — plot.SDTree","text":"x Fitted object class SDTree. ... arguments passed methods.","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/plot.SDTree.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot SDTree — plot.SDTree","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/plot.partDependence.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot partial dependence — plot.partDependence","title":"Plot partial dependence — plot.partDependence","text":"function plots partial dependence model single variable.","code":""},{"path":"https://markusul.github.io/SDForest/reference/plot.partDependence.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot partial dependence — plot.partDependence","text":"","code":"# S3 method for partDependence plot(x, n_examples = 19, ...)"},{"path":"https://markusul.github.io/SDForest/reference/plot.partDependence.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot partial dependence — plot.partDependence","text":"x object class partDependence returned partDependence. n_examples Number examples plot addition average prediction. ... arguments passed methods.","code":""},{"path":"https://markusul.github.io/SDForest/reference/plot.partDependence.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot partial dependence — plot.partDependence","text":"ggplot object.","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/plot.partDependence.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Plot partial dependence — plot.partDependence","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/plot.paths.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize the paths of a SDTree or SDForest — plot.paths","title":"Visualize the paths of a SDTree or SDForest — plot.paths","text":"function visualizes variable importance SDTree SDForest different complexity parameters. regularization path stability selection path can visualized.","code":""},{"path":"https://markusul.github.io/SDForest/reference/plot.paths.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize the paths of a SDTree or SDForest — plot.paths","text":"","code":"# S3 method for paths plot(x, plotly = FALSE, selection = NULL, log_scale = FALSE, ...)"},{"path":"https://markusul.github.io/SDForest/reference/plot.paths.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize the paths of a SDTree or SDForest — plot.paths","text":"x paths object plotly TRUE plot returned interactive using plotly. Might slow large data. selection vector indices covariates plotted.  Can used plot subset covariates case many covariates. log_scale TRUE y-axis log scale. ... arguments passed methods.","code":""},{"path":"https://markusul.github.io/SDForest/reference/plot.paths.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize the paths of a SDTree or SDForest — plot.paths","text":"ggplot object variable importance different regularization. path object includes cp_min value, black dashed line added indicate --bag optimal variable selection.","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/plot.paths.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Visualize the paths of a SDTree or SDForest — plot.paths","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/plotOOB.html","id":null,"dir":"Reference","previous_headings":"","what":"Visualize the out-of-bag performance of a SDForest — plotOOB","title":"Visualize the out-of-bag performance of a SDForest — plotOOB","text":"function visualizes --bag performance SDForest different complexity parameters. Can used choose optimal complexity parameter.","code":""},{"path":"https://markusul.github.io/SDForest/reference/plotOOB.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Visualize the out-of-bag performance of a SDForest — plotOOB","text":"","code":"plotOOB(object)"},{"path":"https://markusul.github.io/SDForest/reference/plotOOB.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Visualize the out-of-bag performance of a SDForest — plotOOB","text":"object paths object loss_path matrix  --bag performance complexity parameter.","code":""},{"path":"https://markusul.github.io/SDForest/reference/plotOOB.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Visualize the out-of-bag performance of a SDForest — plotOOB","text":"ggplot object","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/plotOOB.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Visualize the out-of-bag performance of a SDForest — plotOOB","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/predict.SDForest.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictions for the SDForest — predict.SDForest","title":"Predictions for the SDForest — predict.SDForest","text":"Predicts response new data using fitted SDForest.","code":""},{"path":"https://markusul.github.io/SDForest/reference/predict.SDForest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictions for the SDForest — predict.SDForest","text":"","code":"# S3 method for SDForest predict(object, newdata, ...)"},{"path":"https://markusul.github.io/SDForest/reference/predict.SDForest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictions for the SDForest — predict.SDForest","text":"object Fitted object class SDForest. newdata New test data class data.frame containing covariates predict response. ... arguments passed methods.","code":""},{"path":"https://markusul.github.io/SDForest/reference/predict.SDForest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predictions for the SDForest — predict.SDForest","text":"vector predictions new data.","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/predict.SDForest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Predictions for the SDForest — predict.SDForest","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/predict.SDForest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predictions for the SDForest — predict.SDForest","text":"","code":"set.seed(1) n <- 50 X <- matrix(rnorm(n * 20), nrow = n) y <- sign(X[, 1]) * 3 + rnorm(n) model <- SDForest(x = X, y = y, Q_type = 'no_deconfounding', nTree = 10) predict(model, newdata = data.frame(X)) #>  [1] -2.344572  3.320119 -2.846440  2.025373  2.786994 -3.001182  2.440376 #>  [8]  2.719209  2.126194 -1.895545  2.821547  2.882342 -2.401900 -3.379231 #> [15]  3.166384 -1.965881 -2.613395  1.630138  2.481392  2.837458  1.988028 #> [22]  2.347486  2.055098 -2.104640  2.872809 -2.321626 -1.951900 -2.336816 #> [29] -3.037872  1.882414  2.361760 -2.851037  2.183664 -3.224546 -2.357686 #> [36] -2.823924 -2.014919 -1.953223  2.561342  2.832949 -2.650911 -2.599645 #> [43]  2.657280  1.676892 -2.289810 -2.317609  2.703465  2.129185 -1.615429 #> [50]  2.948960"},{"path":"https://markusul.github.io/SDForest/reference/predict.SDTree.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictions for the SDTree — predict.SDTree","title":"Predictions for the SDTree — predict.SDTree","text":"Predicts response new data using fitted SDTree.","code":""},{"path":"https://markusul.github.io/SDForest/reference/predict.SDTree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictions for the SDTree — predict.SDTree","text":"","code":"# S3 method for SDTree predict(object, newdata, ...)"},{"path":"https://markusul.github.io/SDForest/reference/predict.SDTree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictions for the SDTree — predict.SDTree","text":"object Fitted object class SDTree. newdata New test data class data.frame containing  covariates predict response. ... arguments passed methods.","code":""},{"path":"https://markusul.github.io/SDForest/reference/predict.SDTree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predictions for the SDTree — predict.SDTree","text":"vector predictions new data.","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/predict.SDTree.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Predictions for the SDTree — predict.SDTree","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/predict.SDTree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predictions for the SDTree — predict.SDTree","text":"","code":"set.seed(1) n <- 50 X <- matrix(rnorm(n * 20), nrow = n) y <- sign(X[, 1]) * 3 + rnorm(n) model <- SDTree(x = X, y = y, Q_type = 'no_deconfounding') predict(model, newdata = data.frame(X)) #>  [1] -2.638193  3.314347 -2.638193  2.379640  2.379640 -3.705198  3.314347 #>  [8]  2.379640  2.379640 -2.638193  3.314347  3.314347 -3.705198 -3.705198 #> [15]  3.314347 -2.638193 -3.705198  2.379640  3.314347  3.314347  3.314347 #> [22]  3.314347  3.314347 -3.705198  3.314347 -3.705198 -3.705198 -2.638193 #> [29] -2.638193  3.314347  2.379640 -3.705198  3.314347 -2.638193 -3.705198 #> [36] -2.638193 -2.638193 -2.638193  3.314347  2.379640 -2.638193 -2.638193 #> [43]  2.379640  3.314347 -2.638193 -2.638193  3.314347  2.379640 -2.638193 #> [50]  3.314347"},{"path":"https://markusul.github.io/SDForest/reference/predictOOB.html","id":null,"dir":"Reference","previous_headings":"","what":"Out-of-bag predictions for the SDForest — predictOOB","title":"Out-of-bag predictions for the SDForest — predictOOB","text":"Predicts response training data  using trees SDForest  trained observation.","code":""},{"path":"https://markusul.github.io/SDForest/reference/predictOOB.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Out-of-bag predictions for the SDForest — predictOOB","text":"","code":"predictOOB(object, X = NULL)"},{"path":"https://markusul.github.io/SDForest/reference/predictOOB.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Out-of-bag predictions for the SDForest — predictOOB","text":"object Fitted object class SDForest. X Covariates training data. NULL, data saved object used.","code":""},{"path":"https://markusul.github.io/SDForest/reference/predictOOB.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Out-of-bag predictions for the SDForest — predictOOB","text":"vector --bag predictions training data.","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/predictOOB.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Out-of-bag predictions for the SDForest — predictOOB","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/print.SDForest.html","id":null,"dir":"Reference","previous_headings":"","what":"Print SDForest — print.SDForest","title":"Print SDForest — print.SDForest","text":"Print contents SDForest.","code":""},{"path":"https://markusul.github.io/SDForest/reference/print.SDForest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print SDForest — print.SDForest","text":"","code":"# S3 method for SDForest print(x, ...)"},{"path":"https://markusul.github.io/SDForest/reference/print.SDForest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print SDForest — print.SDForest","text":"x Fitted object class SDForest. ... arguments passed methods.","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/print.SDForest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print SDForest — print.SDForest","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/print.SDTree.html","id":null,"dir":"Reference","previous_headings":"","what":"Print a SDTree — print.SDTree","title":"Print a SDTree — print.SDTree","text":"Print contents SDTree.","code":""},{"path":"https://markusul.github.io/SDForest/reference/print.SDTree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Print a SDTree — print.SDTree","text":"","code":"# S3 method for SDTree print(x, ...)"},{"path":"https://markusul.github.io/SDForest/reference/print.SDTree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Print a SDTree — print.SDTree","text":"x Fitted object class SDTree. ... arguments passed methods.","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/print.SDTree.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Print a SDTree — print.SDTree","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/prune.SDForest.html","id":null,"dir":"Reference","previous_headings":"","what":"Prune a SDForest — prune.SDForest","title":"Prune a SDForest — prune.SDForest","text":"Prunes trees forest re-calculates --bag predictions performance measures. training data needed calculate --bag statistics. Note forest pruned place. intend keep original forest, make copy pruning.","code":""},{"path":"https://markusul.github.io/SDForest/reference/prune.SDForest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prune a SDForest — prune.SDForest","text":"","code":"# S3 method for SDForest prune(object, cp, X = NULL, Y = NULL, Q = NULL, pred = TRUE, ...)"},{"path":"https://markusul.github.io/SDForest/reference/prune.SDForest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prune a SDForest — prune.SDForest","text":"object SDForest object cp Complexity parameter, higher value nodes pruned. X training data, NULL data forest object used. Y training response variable, NULL data forest object used. Q transformation matrix, NULL data forest object used. pred TRUE predictions calculated, FALSE --bag statistics calculated. can set FALSE save computation time --bag statistics needed. ... arguments passed methods.","code":""},{"path":"https://markusul.github.io/SDForest/reference/prune.SDForest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prune a SDForest — prune.SDForest","text":"pruned SDForest object","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/prune.SDForest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prune a SDForest — prune.SDForest","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/prune.SDTree.html","id":null,"dir":"Reference","previous_headings":"","what":"Prune a SDTree — prune.SDTree","title":"Prune a SDTree — prune.SDTree","text":"Removes nodes improve loss cp times initial loss.  Either one successors. Note tree pruned place. intend keep original tree, make copy pruning.","code":""},{"path":"https://markusul.github.io/SDForest/reference/prune.SDTree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prune a SDTree — prune.SDTree","text":"","code":"# S3 method for SDTree prune(object, cp, ...)"},{"path":"https://markusul.github.io/SDForest/reference/prune.SDTree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prune a SDTree — prune.SDTree","text":"object SDTree object cp Complexity parameter, higher value nodes pruned. ... arguments passed methods.","code":""},{"path":"https://markusul.github.io/SDForest/reference/prune.SDTree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prune a SDTree — prune.SDTree","text":"pruned SDTree object","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/prune.SDTree.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Prune a SDTree — prune.SDTree","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/prune.SDTree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Prune a SDTree — prune.SDTree","text":"","code":"set.seed(1) X <- matrix(rnorm(50 * 20), nrow = 50) Y <- rnorm(50) tree <- SDTree(x = X, y = Y) pruned_tree <- prune(copy(tree), 0.2) tree #>                levelName       value           s  j        label decision #> 1  1                     -0.02081201 -0.93604580 18 X18 <= -0.94          #> 2   ¦--1                 -0.77941928          NA NA         -0.8       no #> 3   °--2                  0.12093938  1.17472116 11  X11 <= 1.17      yes #> 4       ¦--2             -0.04070599 -0.35286130  7  X7 <= -0.35       no #> 5       ¦   ¦--2         -0.49011108 -1.03592331  7  X7 <= -1.04       no #> 6       ¦   ¦   ¦--2      0.23561437          NA NA          0.2       no #> 7       ¦   ¦   °--5     -1.02079127          NA NA           -1      yes #> 8       ¦   °--4          0.23071408 -0.04503261  9  X9 <= -0.05      yes #> 9       ¦       ¦--4      0.56328417  0.56462648  6   X6 <= 0.56       no #> 10      ¦       ¦   ¦--4  0.79656934          NA NA          0.8       no #> 11      ¦       ¦   °--7  0.25191655          NA NA          0.3      yes #> 12      ¦       °--6     -0.25462995          NA NA         -0.3      yes #> 13      °--3              1.35957973          NA NA          1.4      yes #>    n_samples #> 1         50 #> 2          8 #> 3         42 #> 4         37 #> 5         14 #> 6          6 #> 7          8 #> 8         23 #> 9         14 #> 10         8 #> 11         6 #> 12         9 #> 13         5 pruned_tree #>   levelName       value          s  j label decision n_samples #> 1         1 -0.02081201 -0.9360458 18     0       NA        50"},{"path":"https://markusul.github.io/SDForest/reference/regPath.SDForest.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the regularization path of a SDForest — regPath.SDForest","title":"Calculate the regularization path of a SDForest — regPath.SDForest","text":"function calculates variable importance SDForest --bag performance different complexity parameters.","code":""},{"path":"https://markusul.github.io/SDForest/reference/regPath.SDForest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the regularization path of a SDForest — regPath.SDForest","text":"","code":"# S3 method for SDForest regPath(object, cp_seq = NULL, X = NULL, Y = NULL, Q = NULL, ...)"},{"path":"https://markusul.github.io/SDForest/reference/regPath.SDForest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the regularization path of a SDForest — regPath.SDForest","text":"object SDForest object cp_seq sequence complexity parameters. NULL, sequence calculated automatically using relevant values. X training data, NULL data forest object used. Y training response variable, NULL data forest object used. Q transformation matrix, NULL data forest object used. ... arguments passed methods.","code":""},{"path":"https://markusul.github.io/SDForest/reference/regPath.SDForest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the regularization path of a SDForest — regPath.SDForest","text":"object class paths containing cp sequence complexity parameters. varImp_path matrix variable importance complexity parameter. loss_path matrix --bag performance complexity parameter. cp_min complexity parameter lowest --bag performance.","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/regPath.SDForest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate the regularization path of a SDForest — regPath.SDForest","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/regPath.SDForest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the regularization path of a SDForest — regPath.SDForest","text":"","code":"set.seed(1) n <- 10 X <- matrix(rnorm(n * 5), nrow = n) y <- sign(X[, 1]) * 3 + sign(X[, 2]) + rnorm(n) model <- SDForest(x = X, y = y, Q_type = 'no_deconfounding') paths <- regPath(model) plotOOB(paths)  plot(paths)  if (FALSE) { plot(paths, plotly = TRUE) }"},{"path":"https://markusul.github.io/SDForest/reference/regPath.SDTree.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the regularization path of a SDTree — regPath.SDTree","title":"Calculate the regularization path of a SDTree — regPath.SDTree","text":"function calculates variable importance SDTree different complexity parameters.","code":""},{"path":"https://markusul.github.io/SDForest/reference/regPath.SDTree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the regularization path of a SDTree — regPath.SDTree","text":"","code":"# S3 method for SDTree regPath(object, cp_seq = NULL, ...)"},{"path":"https://markusul.github.io/SDForest/reference/regPath.SDTree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the regularization path of a SDTree — regPath.SDTree","text":"object SDTree object cp_seq sequence complexity parameters. NULL, sequence calculated automatically using relevant values. ... arguments passed methods.","code":""},{"path":"https://markusul.github.io/SDForest/reference/regPath.SDTree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the regularization path of a SDTree — regPath.SDTree","text":"object class paths containing cp sequence complexity parameters. varImp_path matrix variable importance complexity parameter.","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/regPath.SDTree.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate the regularization path of a SDTree — regPath.SDTree","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/regPath.SDTree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the regularization path of a SDTree — regPath.SDTree","text":"","code":"set.seed(1) n <- 10 X <- matrix(rnorm(n * 5), nrow = n) y <- sign(X[, 1]) * 3 + sign(X[, 2]) + rnorm(n) model <- SDTree(x = X, y = y, Q_type = 'no_deconfounding') paths <- regPath(model) plot(paths)  if (FALSE) { plot(paths, plotly = TRUE) }"},{"path":"https://markusul.github.io/SDForest/reference/simulate_data_nonlinear.html","id":null,"dir":"Reference","previous_headings":"","what":"Simulate data with linear confounding and non-linear causal effect — simulate_data_nonlinear","title":"Simulate data with linear confounding and non-linear causal effect — simulate_data_nonlinear","text":"Simulation data confounded non-linear model.  data generating process given : $$Y = f(X) + H \\delta + \\nu$$ $$X = H \\Gamma + E$$ \\(f(X)\\) random function fourier basis subset size m covariates \\(X_j\\) causal effect \\(Y\\). $$f(x_i) = \\sum_{j = 1}^p 1_{j \\js} \\sum_{k = 1}^K \\beta_{j, k, 1}^{(1)} \\cos(0.1 k x_j) +  \\beta_{j, k, 2}^{(2)} \\sin(0.1 k x_j)$$ \\(E\\), \\(\\nu\\) random error terms  \\(H \\\\mathbb{R}^{n \\times q}\\) matrix random confounding covariates. \\(\\Gamma \\\\mathbb{R}^{q \\times p}\\) \\(\\delta \\\\mathbb{R}^{q}\\) random coefficient vectors. simulation, parameters drawn standard normal distribution, except  \\(\\nu\\) drawn normal distribution standard deviation 0.1. parameters \\(\\beta\\) drawn uniform distribution -1 1.","code":""},{"path":"https://markusul.github.io/SDForest/reference/simulate_data_nonlinear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Simulate data with linear confounding and non-linear causal effect — simulate_data_nonlinear","text":"","code":"simulate_data_nonlinear(q, p, n, m, eff = NULL)"},{"path":"https://markusul.github.io/SDForest/reference/simulate_data_nonlinear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Simulate data with linear confounding and non-linear causal effect — simulate_data_nonlinear","text":"q number confounding covariates H p number covariates X n number observations m number covariates causal effect Y eff number affected covariates X confounding, NULL covariates affected","code":""},{"path":"https://markusul.github.io/SDForest/reference/simulate_data_nonlinear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Simulate data with linear confounding and non-linear causal effect — simulate_data_nonlinear","text":"list containing simulated data: X matrix covariates Y vector responses f_X vector true function f(X) j indices causal covariates X beta parameter vector function f(X) , see f_four H matrix confounding covariates","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/simulate_data_nonlinear.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Simulate data with linear confounding and non-linear causal effect — simulate_data_nonlinear","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/stabilitySelection.SDForest.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the stability selection of a SDForest — stabilitySelection.SDForest","title":"Calculate the stability selection of a SDForest — stabilitySelection.SDForest","text":"function calculates stability selection SDForest (Meinshausen Bühlmann 2010) . Stability selection calculated fraction trees forest select variable split complexity parameter.","code":""},{"path":"https://markusul.github.io/SDForest/reference/stabilitySelection.SDForest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the stability selection of a SDForest — stabilitySelection.SDForest","text":"","code":"# S3 method for SDForest stabilitySelection(object, cp_seq = NULL, ...)"},{"path":"https://markusul.github.io/SDForest/reference/stabilitySelection.SDForest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the stability selection of a SDForest — stabilitySelection.SDForest","text":"object SDForest object cp_seq sequence complexity parameters. NULL, sequence calculated automatically using relevant values. ... arguments passed methods.","code":""},{"path":"https://markusul.github.io/SDForest/reference/stabilitySelection.SDForest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the stability selection of a SDForest — stabilitySelection.SDForest","text":"object class paths containing cp sequence complexity parameters. varImp_path matrix stability selection complexity parameter.","code":""},{"path":"https://markusul.github.io/SDForest/reference/stabilitySelection.SDForest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Calculate the stability selection of a SDForest — stabilitySelection.SDForest","text":"Meinshausen N, Bühlmann P (2010). “Stability Selection.” Journal Royal Statistical Society Series B: Statistical Methodology, 72(4), 417--473. ISSN 1369-7412, doi:10.1111/j.1467-9868.2010.00740.x .","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/stabilitySelection.SDForest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Calculate the stability selection of a SDForest — stabilitySelection.SDForest","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/stabilitySelection.SDForest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Calculate the stability selection of a SDForest — stabilitySelection.SDForest","text":"","code":"set.seed(1) n <- 10 X <- matrix(rnorm(n * 5), nrow = n) y <- sign(X[, 1]) * 3 + sign(X[, 2]) + rnorm(n) model <- SDForest(x = X, y = y, Q_type = 'no_deconfounding') paths <- stabilitySelection(model) plot(paths)  if (FALSE) { plot(paths, plotly = TRUE) }"},{"path":"https://markusul.github.io/SDForest/reference/toList.SDForest.html","id":null,"dir":"Reference","previous_headings":"","what":"SDForest toList method — toList.SDForest","title":"SDForest toList method — toList.SDForest","text":"Converts trees SDForest object class Node (Glur 2023)  class list. makes substantially easier save forest disk.","code":""},{"path":"https://markusul.github.io/SDForest/reference/toList.SDForest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SDForest toList method — toList.SDForest","text":"","code":"# S3 method for SDForest toList(object, ...)"},{"path":"https://markusul.github.io/SDForest/reference/toList.SDForest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"SDForest toList method — toList.SDForest","text":"object SDForest object trees Node format ... arguments passed methods.","code":""},{"path":"https://markusul.github.io/SDForest/reference/toList.SDForest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"SDForest toList method — toList.SDForest","text":"SDForest object trees list format","code":""},{"path":"https://markusul.github.io/SDForest/reference/toList.SDForest.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"SDForest toList method — toList.SDForest","text":"Glur C (2023). “data.tree: General Purpose Hierarchical Data Structure.” https://CRAN.R-project.org/package=data.tree.","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/toList.SDForest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"SDForest toList method — toList.SDForest","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/toList.SDTree.html","id":null,"dir":"Reference","previous_headings":"","what":"SDTree toList method — toList.SDTree","title":"SDTree toList method — toList.SDTree","text":"Converts tree SDTree object  class Node (Glur 2023)  class list. makes substantially easier save tree disk.","code":""},{"path":"https://markusul.github.io/SDForest/reference/toList.SDTree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"SDTree toList method — toList.SDTree","text":"","code":"# S3 method for SDTree toList(object, ...)"},{"path":"https://markusul.github.io/SDForest/reference/toList.SDTree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"SDTree toList method — toList.SDTree","text":"object SDTree object tree Node format ... arguments passed methods.","code":""},{"path":"https://markusul.github.io/SDForest/reference/toList.SDTree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"SDTree toList method — toList.SDTree","text":"SDTree object tree list format","code":""},{"path":"https://markusul.github.io/SDForest/reference/toList.SDTree.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"SDTree toList method — toList.SDTree","text":"Glur C (2023). “data.tree: General Purpose Hierarchical Data Structure.” https://CRAN.R-project.org/package=data.tree.","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/toList.SDTree.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"SDTree toList method — toList.SDTree","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/varImp.SDForest.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract variable importance of a SDForest — varImp.SDForest","title":"Extract variable importance of a SDForest — varImp.SDForest","text":"function extracts variable importance SDForest. variable importance calculated mean variable importance trees forest.","code":""},{"path":"https://markusul.github.io/SDForest/reference/varImp.SDForest.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract variable importance of a SDForest — varImp.SDForest","text":"","code":"# S3 method for SDForest varImp(object)"},{"path":"https://markusul.github.io/SDForest/reference/varImp.SDForest.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract variable importance of a SDForest — varImp.SDForest","text":"object SDForest object","code":""},{"path":"https://markusul.github.io/SDForest/reference/varImp.SDForest.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract variable importance of a SDForest — varImp.SDForest","text":"named vector variable importance","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/varImp.SDForest.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract variable importance of a SDForest — varImp.SDForest","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/varImp.SDForest.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract variable importance of a SDForest — varImp.SDForest","text":"","code":"data(iris) fit <- SDForest(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width,                   iris, nTree = 10) varImp(fit) #>  Sepal.Width Petal.Length  Petal.Width  #>     2.512698     1.695477     4.096719"},{"path":"https://markusul.github.io/SDForest/reference/varImp.SDTree.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract variable importance of a SDTree — varImp.SDTree","title":"Extract variable importance of a SDTree — varImp.SDTree","text":"function extracts variable importance SDTree.  variable importance calculated sum decrease  loss function resulting splits use variable.","code":""},{"path":"https://markusul.github.io/SDForest/reference/varImp.SDTree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract variable importance of a SDTree — varImp.SDTree","text":"","code":"# S3 method for SDTree varImp(object)"},{"path":"https://markusul.github.io/SDForest/reference/varImp.SDTree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract variable importance of a SDTree — varImp.SDTree","text":"object SDTree object","code":""},{"path":"https://markusul.github.io/SDForest/reference/varImp.SDTree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract variable importance of a SDTree — varImp.SDTree","text":"named vector variable importance","code":""},{"path":[]},{"path":"https://markusul.github.io/SDForest/reference/varImp.SDTree.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Extract variable importance of a SDTree — varImp.SDTree","text":"Markus Ulmer","code":""},{"path":"https://markusul.github.io/SDForest/reference/varImp.SDTree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract variable importance of a SDTree — varImp.SDTree","text":"","code":"data(iris) tree <- SDTree(Sepal.Length ~ Sepal.Width + Petal.Length + Petal.Width, iris) varImp(tree) #>  Sepal.Width Petal.Length  Petal.Width  #>     0.000000     8.018457     0.000000"}]
