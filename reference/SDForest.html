<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Spectrally Deconfounded Random Forests — SDForest • SDForest</title><!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png"><link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png"><link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png"><link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png"><link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png"><link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png"><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Spectrally Deconfounded Random Forests — SDForest"><meta property="og:description" content="Estimate regression Random Forest using spectral deconfounding.
The spectrally deconfounded Random Forest (SDForest) combines SDTrees in the same way,
as in the original Random Forest (Breiman 2001)
.
The idea is to combine multiple regression trees into an ensemble in order to
decrease variance and get a smooth function. Ensembles work best if the different
models are independent of each other. To decorrelate the regression trees as much
as possible from each other, we have two mechanisms. The first one is bagging
(Breiman 1996)
, where we train each regression
tree on an independent bootstrap sample of the observations, e.g., we draw a
random sample of size \(n\) with replacement from the observations.
The second mechanic to decrease the correlation is that only a random subset
of the covariates is available for each split. Before each split,
we sample \(\text{mtry} \leq p\) from all the covariates and choose the one
that reduces the loss the most only from those.
$$\widehat{f(X)} = \frac{1}{N_{tree}} \sum_{t = 1}^{N_{tree}} SDTree_t(X)$$"><meta property="og:image" content="https://markusul.github.io/SDForest/logo.png"><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">


    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">SDForest</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../articles/SDForest.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles

    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/Runtime.html">Runtime</a>
    </li>
    <li>
      <a href="../articles/SDTree.html">SDTree</a>
    </li>
  </ul></li>
      </ul><ul class="nav navbar-nav navbar-right"></ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->



      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Spectrally Deconfounded Random Forests</h1>

    <div class="hidden name"><code>SDForest.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Estimate regression Random Forest using spectral deconfounding.
The spectrally deconfounded Random Forest (SDForest) combines SDTrees in the same way,
as in the original Random Forest (Breiman 2001)
.
The idea is to combine multiple regression trees into an ensemble in order to
decrease variance and get a smooth function. Ensembles work best if the different
models are independent of each other. To decorrelate the regression trees as much
as possible from each other, we have two mechanisms. The first one is bagging
(Breiman 1996)
, where we train each regression
tree on an independent bootstrap sample of the observations, e.g., we draw a
random sample of size \(n\) with replacement from the observations.
The second mechanic to decrease the correlation is that only a random subset
of the covariates is available for each split. Before each split,
we sample \(\text{mtry} \leq p\) from all the covariates and choose the one
that reduces the loss the most only from those.
$$\widehat{f(X)} = \frac{1}{N_{tree}} \sum_{t = 1}^{N_{tree}} SDTree_t(X)$$</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">SDForest</span><span class="op">(</span></span>
<span>  formula <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  data <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  x <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  y <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  nTree <span class="op">=</span> <span class="fl">100</span>,</span>
<span>  cp <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  min_sample <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  mtry <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  mc.cores <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  Q_type <span class="op">=</span> <span class="st">"trim"</span>,</span>
<span>  trim_quantile <span class="op">=</span> <span class="fl">0.5</span>,</span>
<span>  q_hat <span class="op">=</span> <span class="fl">0</span>,</span>
<span>  Q <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  A <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  gamma <span class="op">=</span> <span class="fl">7</span>,</span>
<span>  max_size <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  gpu <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  return_data <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  mem_size <span class="op">=</span> <span class="fl">1e+07</span>,</span>
<span>  leave_out_ind <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  envs <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  nTree_leave_out <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  nTree_env <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  max_candidates <span class="op">=</span> <span class="fl">100</span></span>
<span><span class="op">)</span></span></code></pre></div>
    </div>

    <div id="arguments">
    <h2>Arguments</h2>


<dl><dt id="arg-formula">formula<a class="anchor" aria-label="anchor" href="#arg-formula"></a></dt>
<dd><p>Object of class <code>formula</code> or describing the model to fit
of the form <code>y ~ x1 + x2 + ...</code> where <code>y</code> is a numeric response and
<code>x1, x2, ...</code> are vectors of covariates. Interactions are not supported.</p></dd>


<dt id="arg-data">data<a class="anchor" aria-label="anchor" href="#arg-data"></a></dt>
<dd><p>Training data of class <code>data.frame</code> containing the variables in the model.</p></dd>


<dt id="arg-x">x<a class="anchor" aria-label="anchor" href="#arg-x"></a></dt>
<dd><p>Matrix of covariates, alternative to <code>formula</code> and <code>data</code>.</p></dd>


<dt id="arg-y">y<a class="anchor" aria-label="anchor" href="#arg-y"></a></dt>
<dd><p>Vector of responses, alternative to <code>formula</code> and <code>data</code>.</p></dd>


<dt id="arg-ntree">nTree<a class="anchor" aria-label="anchor" href="#arg-ntree"></a></dt>
<dd><p>Number of trees to grow.</p></dd>


<dt id="arg-cp">cp<a class="anchor" aria-label="anchor" href="#arg-cp"></a></dt>
<dd><p>Complexity parameter, minimum loss decrease to split a node.
A split is only performed if the loss decrease is larger than <code>cp * initial_loss</code>,
where <code>initial_loss</code> is the loss of the initial estimate using only a stump.</p></dd>


<dt id="arg-min-sample">min_sample<a class="anchor" aria-label="anchor" href="#arg-min-sample"></a></dt>
<dd><p>Minimum number of observations per leaf.
A split is only performed if both resulting leaves have at least
<code>min_sample</code> observations.</p></dd>


<dt id="arg-mtry">mtry<a class="anchor" aria-label="anchor" href="#arg-mtry"></a></dt>
<dd><p>Number of randomly selected covariates to consider for a split,
if <code>NULL</code> half of the covariates are available for each split.
\(\text{mtry} = \lfloor \frac{p}{2} \rfloor\)</p></dd>


<dt id="arg-mc-cores">mc.cores<a class="anchor" aria-label="anchor" href="#arg-mc-cores"></a></dt>
<dd><p>Number of cores to use for parallel processing,
if <code>mc.cores &gt; 1</code> the trees are estimated in parallel.</p></dd>


<dt id="arg-q-type">Q_type<a class="anchor" aria-label="anchor" href="#arg-q-type"></a></dt>
<dd><p>Type of deconfounding, one of 'trim', 'pca', 'no_deconfounding'.
'trim' corresponds to the Trim transform (Ćevid et al. 2020)

as implemented in the Doubly debiased lasso (Guo et al. 2022)
,
'pca' to the PCA transformation(Paul et al. 2008)
.
See <code><a href="get_Q.html">get_Q</a></code>.</p></dd>


<dt id="arg-trim-quantile">trim_quantile<a class="anchor" aria-label="anchor" href="#arg-trim-quantile"></a></dt>
<dd><p>Quantile for Trim transform,
only needed for trim, see <code><a href="get_Q.html">get_Q</a></code>.</p></dd>


<dt id="arg-q-hat">q_hat<a class="anchor" aria-label="anchor" href="#arg-q-hat"></a></dt>
<dd><p>Assumed confounding dimension, only needed for pca,
see <code><a href="get_Q.html">get_Q</a></code>.</p></dd>


<dt id="arg-q">Q<a class="anchor" aria-label="anchor" href="#arg-q"></a></dt>
<dd><p>Spectral transformation, if <code>NULL</code>
it is internally estimated using <code><a href="get_Q.html">get_Q</a></code>.</p></dd>


<dt id="arg-a">A<a class="anchor" aria-label="anchor" href="#arg-a"></a></dt>
<dd><p>Numerical Anchor of class <code>matrix</code>. See <code><a href="get_W.html">get_W</a></code>.</p></dd>


<dt id="arg-gamma">gamma<a class="anchor" aria-label="anchor" href="#arg-gamma"></a></dt>
<dd><p>Strength of distributional robustness, \(\gamma \in [0, \infty]\).
See <code><a href="get_W.html">get_W</a></code>.</p></dd>


<dt id="arg-max-size">max_size<a class="anchor" aria-label="anchor" href="#arg-max-size"></a></dt>
<dd><p>Maximum number of observations used for a bootstrap sample.
If <code>NULL</code> n samples with replacement are drawn.</p></dd>


<dt id="arg-gpu">gpu<a class="anchor" aria-label="anchor" href="#arg-gpu"></a></dt>
<dd><p>If <code>TRUE</code>, the calculations are performed on the GPU.
If it is properly set up.</p></dd>


<dt id="arg-return-data">return_data<a class="anchor" aria-label="anchor" href="#arg-return-data"></a></dt>
<dd><p>If <code>TRUE</code>, the training data is returned in the output.
This is needed for <code><a href="prune.SDForest.html">prune.SDForest</a></code>, <code><a href="regPath.SDForest.html">regPath.SDForest</a></code>,
and for <code><a href="mergeForest.html">mergeForest</a></code>.</p></dd>


<dt id="arg-mem-size">mem_size<a class="anchor" aria-label="anchor" href="#arg-mem-size"></a></dt>
<dd><p>Amount of split candidates that can be evaluated at once.
This is a trade-off between memory and speed can be decreased if either
the memory is not sufficient or the gpu is to small.</p></dd>


<dt id="arg-leave-out-ind">leave_out_ind<a class="anchor" aria-label="anchor" href="#arg-leave-out-ind"></a></dt>
<dd><p>Indices of observations that should not be used for training.</p></dd>


<dt id="arg-envs">envs<a class="anchor" aria-label="anchor" href="#arg-envs"></a></dt>
<dd><p>Vector of environments of class <code>factor</code>
which can be used for stratified tree fitting.</p></dd>


<dt id="arg-ntree-leave-out">nTree_leave_out<a class="anchor" aria-label="anchor" href="#arg-ntree-leave-out"></a></dt>
<dd><p>Number of trees that should be estimated while leaving
one of the environments out. Results in number of environments times number of trees.</p></dd>


<dt id="arg-ntree-env">nTree_env<a class="anchor" aria-label="anchor" href="#arg-ntree-env"></a></dt>
<dd><p>Number of trees that should be estimated for each environment.
Results in number of environments times number of trees.</p></dd>


<dt id="arg-max-candidates">max_candidates<a class="anchor" aria-label="anchor" href="#arg-max-candidates"></a></dt>
<dd><p>Maximum number of split points that are
proposed at each node for each covariate.</p></dd>

</dl></div>
    <div id="value">
    <h2>Value</h2>
    <p>Object of class <code>SDForest</code> containing:</p>
<dl><dt>predictions</dt>
<dd><p>Vector of predictions for each observation.</p></dd>

<dt>forest</dt>
<dd><p>List of SDTree objects.</p></dd>

<dt>var_names</dt>
<dd><p>Names of the covariates.</p></dd>

<dt>oob_loss</dt>
<dd><p>Out-of-bag loss. MSE</p></dd>

<dt>oob_SDloss</dt>
<dd><p>Out-of-bag loss using the spectral transformation.</p></dd>

<dt>var_importance</dt>
<dd><p>Variable importance.
The variable importance is calculated as the sum of the decrease in the loss function
resulting from all splits that use a covariate for each tree.
The mean of the variable importance of all trees results in the variable importance for the forest.</p></dd>

<dt>oob_ind</dt>
<dd><p>List of indices of trees that did not contain the observation in the training set.</p></dd>

<dt>oob_predictions</dt>
<dd><p>Out-of-bag predictions.</p></dd>

</dl><p>If <code>return_data</code> is <code>TRUE</code> the following are also returned:</p>
<dl><dt>X</dt>
<dd><p>Matrix of covariates.</p></dd>

<dt>Y</dt>
<dd><p>Vector of responses.</p></dd>

<dt>Q</dt>
<dd><p>Spectral transformation matrix.</p></dd>

</dl><p>If <code>envs</code> is provided the following are also returned:</p>
<dl><dt>envs</dt>
<dd><p>Vector of environments.</p></dd>

<dt>nTree_env</dt>
<dd><p>Number of trees for each environment.</p></dd>

<dt>ooEnv_ind</dt>
<dd><p>List of indices of trees that did not contain the observation or the same environment in the training set
for each observation.</p></dd>

<dt>ooEnv_loss</dt>
<dd><p>Out-of-bag loss using only trees that did not contain the observation or the same environment.</p></dd>

<dt>ooEnv_SDloss</dt>
<dd><p>Out-of-bag loss using the spectral transformation and only trees that did not contain the observation
or the same environment.</p></dd>

<dt>ooEnv_predictions</dt>
<dd><p>Out-of-bag predictions using only trees that did not contain the observation or the same environment.</p></dd>

<dt>nTree_leave_out</dt>
<dd><p>If environments are left out, the environment for each tree, that was left out.</p></dd>

<dt>nTree_env</dt>
<dd><p>If environments are provided, the environment each tree is trained with.</p></dd>

</dl></div>
    <div id="references">
    <h2>References</h2>
    <p>Breiman L (1996).
“Bagging predictors.”
<em>Machine Learning</em>, <b>24</b>(2), 123–140.
ISSN 0885-6125, <a href="https://doi.org/10.1007/BF00058655" class="external-link">doi:10.1007/BF00058655</a>
.<br><br> Breiman L (2001).
“Random Forests.”
<em>Machine Learning</em>, <b>45</b>(1), 5–32.
ISSN 08856125, <a href="https://doi.org/10.1023/A%3A1010933404324" class="external-link">doi:10.1023/A:1010933404324</a>
.<br><br> Ćevid D, Bühlmann P, Meinshausen N (2020).
“Spectral Deconfounding via Perturbed Sparse Linear Models.”
<em>J. Mach. Learn. Res.</em>, <b>21</b>(1).
ISSN 1532-4435.<br><br> Guo Z, Ćevid D, Bühlmann P (2022).
“Doubly debiased lasso: High-dimensional inference under hidden confounding.”
<em>The Annals of Statistics</em>, <b>50</b>(3).
ISSN 0090-5364, <a href="https://doi.org/10.1214/21-AOS2152" class="external-link">doi:10.1214/21-AOS2152</a>
.<br><br> Paul D, Bair E, Hastie T, Tibshirani R (2008).
““Preconditioning” for feature selection and regression in high-dimensional problems.”
<em>The Annals of Statistics</em>, <b>36</b>(4).
ISSN 0090-5364, <a href="https://doi.org/10.1214/009053607000000578" class="external-link">doi:10.1214/009053607000000578</a>
.</p>
    </div>
    <div id="see-also">
    <h2>See also</h2>
    <div class="dont-index"><p><code><a href="get_Q.html">get_Q</a></code>, <code><a href="get_W.html">get_W</a></code>, <code><a href="SDTree.html">SDTree</a></code>,
<code><a href="simulate_data_nonlinear.html">simulate_data_nonlinear</a></code>, <code><a href="regPath.SDForest.html">regPath</a></code>,
<code><a href="stabilitySelection.SDForest.html">stabilitySelection</a></code>, <code><a href="prune.SDForest.html">prune</a></code>, <code><a href="partDependence.html">partDependence</a></code></p></div>
    </div>
    <div id="author">
    <h2>Author</h2>
    <p>Markus Ulmer</p>
    </div>

    <div id="ref-examples">
    <h2>Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">42</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># simulation of confounded data</span></span></span>
<span class="r-in"><span><span class="va">sim_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="simulate_data_nonlinear.html">simulate_data_nonlinear</a></span><span class="op">(</span>q <span class="op">=</span> <span class="fl">2</span>, p <span class="op">=</span> <span class="fl">150</span>, n <span class="op">=</span> <span class="fl">100</span>, m <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">X</span> <span class="op">&lt;-</span> <span class="va">sim_data</span><span class="op">$</span><span class="va">X</span></span></span>
<span class="r-in"><span><span class="va">Y</span> <span class="op">&lt;-</span> <span class="va">sim_data</span><span class="op">$</span><span class="va">Y</span></span></span>
<span class="r-in"><span><span class="va">train_data</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html" class="external-link">data.frame</a></span><span class="op">(</span><span class="va">X</span>, <span class="va">Y</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># causal parents of y</span></span></span>
<span class="r-in"><span><span class="va">sim_data</span><span class="op">$</span><span class="va">j</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> [1]  88 112</span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># comparison to classical random forest</span></span></span>
<span class="r-in"><span><span class="va">fit_ranger</span> <span class="op">&lt;-</span> <span class="fu">ranger</span><span class="fu">::</span><span class="fu"><a href="http://imbs-hl.github.io/ranger/reference/ranger.html" class="external-link">ranger</a></span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">.</span>, <span class="va">train_data</span>, importance <span class="op">=</span> <span class="st">'impurity'</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu">SDForest</span><span class="op">(</span>x <span class="op">=</span> <span class="va">X</span>, y <span class="op">=</span> <span class="va">Y</span>, nTree <span class="op">=</span> <span class="fl">10</span>, Q_type <span class="op">=</span> <span class="st">'pca'</span>, q_hat <span class="op">=</span> <span class="fl">2</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu">SDForest</span><span class="op">(</span><span class="va">Y</span> <span class="op">~</span> <span class="va">.</span>, <span class="va">train_data</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">fit</span></span></span>
<span class="r-out co"><span class="r-pr">#&gt;</span> SDForest result</span>
<span class="r-out co"><span class="r-pr">#&gt;</span> </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Number of trees:  100 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> Number of covariates:  150 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> OOB loss:  0.66 </span>
<span class="r-out co"><span class="r-pr">#&gt;</span> OOB spectral loss:  0.07 </span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># comparison of variable importance</span></span></span>
<span class="r-in"><span><span class="va">imp_ranger</span> <span class="op">&lt;-</span> <span class="va">fit_ranger</span><span class="op">$</span><span class="va">variable.importance</span></span></span>
<span class="r-in"><span><span class="va">imp_sdf</span> <span class="op">&lt;-</span> <span class="va">fit</span><span class="op">$</span><span class="va">var_importance</span></span></span>
<span class="r-in"><span><span class="va">imp_col</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html" class="external-link">rep</a></span><span class="op">(</span><span class="st">'black'</span>, <span class="fu"><a href="https://rdrr.io/r/base/length.html" class="external-link">length</a></span><span class="op">(</span><span class="va">imp_ranger</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">imp_col</span><span class="op">[</span><span class="va">sim_data</span><span class="op">$</span><span class="va">j</span><span class="op">]</span> <span class="op">&lt;-</span> <span class="st">'red'</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">imp_ranger</span>, <span class="va">imp_sdf</span>, col <span class="op">=</span> <span class="va">imp_col</span>, pch <span class="op">=</span> <span class="fl">20</span>,</span></span>
<span class="r-in"><span>     xlab <span class="op">=</span> <span class="st">'ranger'</span>, ylab <span class="op">=</span> <span class="st">'SDForest'</span>, </span></span>
<span class="r-in"><span>     main <span class="op">=</span> <span class="st">'Variable Importance'</span><span class="op">)</span></span></span>
<span class="r-plt img"><img src="SDForest-1.png" alt="" width="700" height="433"></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># check regularization path of variable importance</span></span></span>
<span class="r-in"><span><span class="va">path</span> <span class="op">&lt;-</span> <span class="fu"><a href="regPath.SDForest.html">regPath</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="co"># out of bag error for different regularization</span></span></span>
<span class="r-in"><span><span class="fu"><a href="plotOOB.html">plotOOB</a></span><span class="op">(</span><span class="va">path</span><span class="op">)</span></span></span>
<span class="r-plt img"><img src="SDForest-2.png" alt="" width="700" height="433"></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">path</span><span class="op">)</span></span></span>
<span class="r-plt img"><img src="SDForest-3.png" alt="" width="700" height="433"></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># detection of causal parent using stability selection</span></span></span>
<span class="r-in"><span><span class="va">stablePath</span> <span class="op">&lt;-</span> <span class="fu"><a href="stabilitySelection.SDForest.html">stabilitySelection</a></span><span class="op">(</span><span class="va">fit</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">stablePath</span><span class="op">)</span></span></span>
<span class="r-plt img"><img src="SDForest-4.png" alt="" width="700" height="433"></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># pruning of forest according to optimal out-of-bag performance</span></span></span>
<span class="r-in"><span><span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu"><a href="prune.SDForest.html">prune</a></span><span class="op">(</span><span class="va">fit</span>, cp <span class="op">=</span> <span class="va">path</span><span class="op">$</span><span class="va">cp_min</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># partial functional dependence of y on the most important covariate</span></span></span>
<span class="r-in"><span><span class="va">most_imp</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/which.min.html" class="external-link">which.max</a></span><span class="op">(</span><span class="va">fit</span><span class="op">$</span><span class="va">var_importance</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">dep</span> <span class="op">&lt;-</span> <span class="fu"><a href="partDependence.html">partDependence</a></span><span class="op">(</span><span class="va">fit</span>, <span class="va">most_imp</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">dep</span>, n_examples <span class="op">=</span> <span class="fl">100</span><span class="op">)</span></span></span>
<span class="r-plt img"><img src="SDForest-5.png" alt="" width="700" height="433"></span>
</code></pre></div>
    </div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Markus Ulmer, Cyrill Scheidegger.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.0.</p>
</div>

      </footer></div>






  </body></html>

