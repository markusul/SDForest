<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="SDForest">
<title>Algorithm • SDForest</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.11/clipboard.min.js" integrity="sha512-7O5pXpc0oCRrxk8RUfDYFgn0nO1t+jLuIOQdOMRp4APB7uZ4vSjspzp5y6YDtDs4VzUSTbWzBFZ/LKJhnyFOKw==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Algorithm">
<meta property="og:description" content="SDForest">
<meta property="og:image" content="https://markusul.github.io/SDForest/logo.png">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light" data-bs-theme="light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">SDForest</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.1</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../articles/SDForest.html">Get started</a>
</li>
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/Algorithm.html">Algorithm</a>
    <a class="dropdown-item" href="../articles/Runtime.html">Runtime</a>
    <a class="dropdown-item" href="../articles/SDTree.html">SDTree</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav"></ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Algorithm</h1>
            
      
      
      <div class="d-none name"><code>Algorithm.Rmd</code></div>
    </div>

    
    
<p>A regression tree is part of the function class of step functions
<span class="math inline">\(f(X) = \sum_{m = 1}^M 1_{\{X \in R_m\}}
c_m\)</span>, where (<span class="math inline">\(R_m\)</span>) with
<span class="math inline">\(m = 1, \ldots, M\)</span> are regions
dividing the space <span class="math inline">\(\mathbb{R}^p\)</span>
into <span class="math inline">\(M\)</span> rectangular parts. Each
region has response level <span class="math inline">\(c_m \in
\mathbb{R}\)</span>. For the training data, we can write the step
function as <span class="math inline">\(f(\mathbf{X}) = \mathcal{P}
c\)</span> where <span class="math inline">\(\mathcal{P} \in \{0, 1\}^{n
\times M}\)</span> is an indicator matrix encoding to which region an
observation belongs to and <span class="math inline">\(c \in
\mathbb{R}^M\)</span> is a vector containing the levels corresponding to
the different regions. An observation can only belong to one region
meaning only one entry per row in <span class="math inline">\(\mathcal{P}\)</span> can be 1: <span class="math inline">\(\text{rowSums}(\mathcal{P}) = 1\)</span>.</p>
<p>This goal is to find</p>
<p><span class="math display">\[(\hat{\mathcal{P}}, \hat{c}) =
\text{argmin}_{\substack{\mathcal{P}' \in \{0, 1\}^{n \times M}, \
c' \in \mathbb{R}^ {M} \\ \text{rowSums}(\mathcal{P'}) = 1}}
\frac{||Q(\mathbf{Y} - \mathcal{P'} c')||_2^2}{n}\]</span> where
<span class="math inline">\(Q\)</span> is a spectral transformation
(<span class="citation">Guo, Ćevid, and Bühlmann (2022)</span>, <span class="citation">Ćevid, Bühlmann, and Meinshausen (2020)</span>).</p>
<p>Since it is unfeasible to iterate over all possible partitions <span class="math inline">\(\mathcal{P}\)</span>, we try to find a reasonable
<span class="math inline">\(\hat{\mathcal{P}}\)</span> by using the tree
structure and repeated splitting of the leaves, similar to the original
cart algorithm <span class="citation">(Breiman et al. 2017)</span>.
Since comparing all possibilities for <span class="math inline">\(\mathcal{P}\)</span> is impossible, we let a tree
grow greedily. Given the current tree, we iterate over all leaves and
all possible splits. We choose the one that reduces the spectral loss
the most, using the SDTree subroutine, and estimate after each split all
the leave estimates <span class="math inline">\(\hat{c} =
\text{argmin}_{c' \in \mathbb{R}^M} \frac{||Q\mathbf{Y} -
Q\mathcal{P} c'||_2^2}{n}\)</span> which is just a linear regression
problem. This is repeated until the loss decreases less than a minimum
loss decrease after a split. The minimum loss decrease equals a
cost-complexity parameter <span class="math inline">\(cp\)</span> times
the initial loss when only an overall mean is estimated. The
cost-complexity parameter <span class="math inline">\(cp\)</span>
controls the complexity of a regression tree and acts as a
regularization parameter.</p>
<p><img src="figures/SDTreeAlg.jpg"></p>
<div class="section level3">
<h3 id="sdtree-subroutine">SDTree subroutine<a class="anchor" aria-label="anchor" href="#sdtree-subroutine"></a>
</h3>
<p>In lines 4-7 of the algorithm, one seeks to find the split <span class="math inline">\((b, j, s)\)</span> among the candidate splits that
lead to the largest decrease <span class="math inline">\(\alpha_{b, j,
s}\)</span> of the spectral objective <span class="math inline">\(\|Q(\mathbf Y - \mathcal P \hat c)\|\)</span>.
Naively, for every candidate split, one would update the indicator
matrix <span class="math inline">\(\mathcal P\)</span>, calculate the
corresponding least squares estimator <span class="math inline">\(\hat
c\)</span> and plug it in to obtain the loss decrease. Using the
following procedure, the decrease in loss can be calculated more
efficiently.</p>
<p>To initialize, set <span class="math inline">\(u_1' = Q\cdot
(1,\ldots, 1)^T\)</span> and <span class="math inline">\(u_1 =
u_1'/\|u_1'\|\)</span>. Inductively, assume now that we are at
step <span class="math inline">\(M\)</span> of the for loop on line 3 of
the algorithm and have defined vectors <span class="math inline">\(u_1,
\ldots, u_M\in \mathbb R^n\)</span>. At this step, we evaluate new
potential splits parameterized by <span class="math inline">\((b, j,
s)\)</span> (see lines 4-6 of the algorithm). The new splits can be
encoded by a vector <span class="math inline">\(e = e^{(b, j,s)}\in
\{0,1\}^n\)</span> with the set <span class="math inline">\(\{j\in
\{1,\ldots, n\}: e_j = 1\}\)</span> being a subset of the set <span class="math inline">\(\{j\in \{1,\ldots, n\}: \hat {\mathcal P}_{j,
m}\}\)</span> for some <span class="math inline">\(m\in \{1, \ldots,
M\}\)</span>. For a candidate split encoded by <span class="math inline">\(e\)</span>, define <span class="math inline">\(u'(e) = (Q-\sum_{l=1}^M u_l u_l^T Q)e\)</span>
and <span class="math inline">\(\alpha(e) = (u'(e)^T
QY)^2/\|u'(e)\|_2^2.\)</span> Then, <span class="math inline">\(\alpha_{b, j, s}\)</span> according to line 6 of
the algorithm is defined by <span class="math inline">\(\alpha_{b, j, s}
:= \alpha(e^{(b, j, s)})\)</span>. Finally, define <span class="math inline">\(u_{M+1} = u'(e^{(b^*, j^*,
s^*)})/\|u'(e^{(b^*, j^*, s^*)})\|_2\)</span> with <span class="math inline">\((b^*, j^*, s^*)\)</span> defined in line 9 of the
algorithm.</p>
</div>
<div class="section level3">
<h3 id="sdforest">SDForest<a class="anchor" aria-label="anchor" href="#sdforest"></a>
</h3>
<p>The spectral deconfounded Random Forest combines SDTrees in the same
way, as in the original Random Forest <span class="citation">(Breiman
2001)</span>. The idea is to combine multiple regression trees into an
ensemble in order to decrease variance and get a smooth function.
Ensembles work best if the different models are independent of each
other. To decorrelate the regression trees as much as possible from each
other, we have two mechanisms. The first one is bagging <span class="citation">(Breiman 1996)</span>, where we train each regression
tree on an independent bootstrap sample of the observations, e.g., we
draw a random sample of size <span class="math inline">\(n\)</span> with
replacement from the observations. The second mechanic to decrease the
correlation is that only a random subset of the covariates is available
for each split. Before each split, we sample <span class="math inline">\(\text{mtry} \leq p\)</span> from all the
covariates and choose the one that reduces the loss the most only from
those.</p>
<p><span class="math display">\[\widehat{f(X)} = \frac{1}{N_{tree}}
\sum_{t = 1}^{N_{tree}} SDTree_t(X^{boot})\]</span></p>
<div id="refs" class="references csl-bib-body hanging-indent" entry-spacing="0">
<div id="ref-Breiman1996BaggingPredictors" class="csl-entry">
Breiman, Leo. 1996. <span>“<span class="nocase">Bagging
predictors</span>.”</span> <em>Machine Learning</em> 24 (2): 123–40. <a href="https://doi.org/10.1007/BF00058655" class="external-link">https://doi.org/10.1007/BF00058655</a>.
</div>
<div id="ref-Breiman2001RandomForests" class="csl-entry">
———. 2001. <span>“<span>Random Forests</span>.”</span> <em>Machine
Learning</em> 45 (1): 5–32. <a href="https://doi.org/10.1023/A:1010933404324" class="external-link">https://doi.org/10.1023/A:1010933404324</a>.
</div>
<div id="ref-Breiman2017ClassificationTrees" class="csl-entry">
Breiman, Leo, Jerome H. Friedman, Richard A. Olshen, and Charles J.
Stone. 2017. <em><span>Classification And Regression Trees</span></em>.
Routledge. <a href="https://doi.org/10.1201/9781315139470" class="external-link">https://doi.org/10.1201/9781315139470</a>.
</div>
<div id="ref-Cevid2020SpectralModels" class="csl-entry">
Ćevid, Domagoj, Peter Bühlmann, and Nicolai Meinshausen. 2020.
<span>“<span class="nocase">Spectral Deconfounding via Perturbed Sparse
Linear Models</span>.”</span> <em>J. Mach. Learn. Res.</em> 21 (1).
</div>
<div id="ref-Guo2022DoublyConfounding" class="csl-entry">
Guo, Zijian, Domagoj Ćevid, and Peter Bühlmann. 2022. <span>“<span class="nocase">Doubly debiased lasso: High-dimensional inference under
hidden confounding</span>.”</span> <em>The Annals of Statistics</em> 50
(3). <a href="https://doi.org/10.1214/21-AOS2152" class="external-link">https://doi.org/10.1214/21-AOS2152</a>.
</div>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Markus Ulmer, Cyrill Scheidegger.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.9.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
